#!/usr/bin/env python3
"""
Complete Ansible Automation Integration for OpsSight Platform
Provides live automation tracking, playbook monitoring, and execution insights
"""

import asyncio
import json
import yaml
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import logging
from pathlib import Path
import subprocess
import tempfile
import os
import random

# Mock Ansible data for development/demo
class MockAnsibleClient:
    """Mock Ansible client that simulates real automation data"""
    
    def __init__(self):
        self.automation_data = self._generate_mock_automation_data()
        
    def _generate_mock_automation_data(self) -> Dict[str, Any]:
        """Generate realistic mock automation data"""
        return {
            "playbooks": [
                {
                    "name": "infrastructure-setup",
                    "path": "/opt/ansible/playbooks/infrastructure-setup.yml",
                    "description": "Complete infrastructure provisioning and configuration",
                    "tags": ["infrastructure", "provisioning", "servers"],
                    "hosts": ["web-servers", "db-servers", "load-balancers"],
                    "tasks_count": 45,
                    "vars_count": 23,
                    "last_run": "2025-01-25T20:30:00Z",
                    "success_rate": 96.2,
                    "avg_duration": 845,  # seconds
                    "total_runs": 127
                },
                {
                    "name": "application-deployment",
                    "path": "/opt/ansible/playbooks/application-deployment.yml", 
                    "description": "Deploy and configure OpsSight application stack",
                    "tags": ["deployment", "application", "docker"],
                    "hosts": ["app-servers"],
                    "tasks_count": 32,
                    "vars_count": 18,
                    "last_run": "2025-01-25T21:15:00Z",
                    "success_rate": 98.5,
                    "avg_duration": 423,
                    "total_runs": 89
                },
                {
                    "name": "security-hardening",
                    "path": "/opt/ansible/playbooks/security-hardening.yml",
                    "description": "Apply security configurations and hardening",
                    "tags": ["security", "hardening", "compliance"],
                    "hosts": ["all"],
                    "tasks_count": 67,
                    "vars_count": 34,
                    "last_run": "2025-01-25T18:45:00Z", 
                    "success_rate": 89.3,
                    "avg_duration": 1234,
                    "total_runs": 45
                },
                {
                    "name": "monitoring-setup",
                    "path": "/opt/ansible/playbooks/monitoring-setup.yml",
                    "description": "Configure Prometheus, Grafana, and monitoring stack",
                    "tags": ["monitoring", "prometheus", "grafana"],
                    "hosts": ["monitoring-servers"],
                    "tasks_count": 28,
                    "vars_count": 15,
                    "last_run": "2025-01-25T19:20:00Z",
                    "success_rate": 94.7,
                    "avg_duration": 567,
                    "total_runs": 34
                },
                {
                    "name": "backup-automation",
                    "path": "/opt/ansible/playbooks/backup-automation.yml",
                    "description": "Automated backup configuration and scheduling",
                    "tags": ["backup", "automation", "disaster-recovery"],
                    "hosts": ["db-servers", "file-servers"],
                    "tasks_count": 19, 
                    "vars_count": 12,
                    "last_run": "2025-01-25T22:00:00Z",
                    "success_rate": 100.0,
                    "avg_duration": 234,
                    "total_runs": 78
                }
            ],
            "executions": [
                {
                    "id": "exec-2025-001-789",
                    "playbook": "application-deployment",
                    "status": "successful",
                    "started_at": "2025-01-25T21:15:00Z",
                    "completed_at": "2025-01-25T21:22:15Z",
                    "duration": 435,
                    "hosts_targeted": 8,
                    "hosts_successful": 8,
                    "hosts_failed": 0,
                    "tasks_completed": 32,
                    "tasks_failed": 0,
                    "changed_tasks": 12,
                    "skipped_tasks": 3,
                    "user": "ansible-automation",
                    "inventory": "production",
                    "extra_vars": {"app_version": "v2.2.0", "environment": "production"}
                },
                {
                    "id": "exec-2025-001-788",
                    "playbook": "infrastructure-setup", 
                    "status": "successful",
                    "started_at": "2025-01-25T20:30:00Z",
                    "completed_at": "2025-01-25T20:44:05Z",
                    "duration": 845,
                    "hosts_targeted": 12,
                    "hosts_successful": 12,
                    "hosts_failed": 0,
                    "tasks_completed": 45,
                    "tasks_failed": 0,
                    "changed_tasks": 23,
                    "skipped_tasks": 7,
                    "user": "devops-team",
                    "inventory": "production",
                    "extra_vars": {"region": "us-east-1", "instance_type": "t3.medium"}
                },
                {
                    "id": "exec-2025-001-787",
                    "playbook": "monitoring-setup",
                    "status": "successful", 
                    "started_at": "2025-01-25T19:20:00Z",
                    "completed_at": "2025-01-25T19:29:27Z",
                    "duration": 567,
                    "hosts_targeted": 3,
                    "hosts_successful": 3,
                    "hosts_failed": 0,
                    "tasks_completed": 28,
                    "tasks_failed": 0,
                    "changed_tasks": 15,
                    "skipped_tasks": 2,
                    "user": "monitoring-team",
                    "inventory": "production",
                    "extra_vars": {"retention_days": "30", "alert_manager": "true"}
                },
                {
                    "id": "exec-2025-001-786",
                    "playbook": "security-hardening",
                    "status": "failed",
                    "started_at": "2025-01-25T18:45:00Z",
                    "completed_at": "2025-01-25T19:05:34Z",
                    "duration": 1234,
                    "hosts_targeted": 15,
                    "hosts_successful": 13,
                    "hosts_failed": 2,
                    "tasks_completed": 59,
                    "tasks_failed": 8,
                    "changed_tasks": 34,
                    "skipped_tasks": 12,
                    "user": "security-team",
                    "inventory": "production",
                    "extra_vars": {"compliance_level": "high", "audit_enabled": "true"},
                    "error_details": [
                        {
                            "host": "web-server-03",
                            "task": "Configure firewall rules",
                            "error": "Failed to apply iptables rule: Chain INPUT does not exist"
                        },
                        {
                            "host": "web-server-07", 
                            "task": "Install security updates",
                            "error": "Package manager lock timeout"
                        }
                    ]
                },
                {
                    "id": "exec-2025-001-785",
                    "playbook": "backup-automation",
                    "status": "successful",
                    "started_at": "2025-01-25T22:00:00Z",
                    "completed_at": "2025-01-25T22:03:54Z", 
                    "duration": 234,
                    "hosts_targeted": 5,
                    "hosts_successful": 5,
                    "hosts_failed": 0,
                    "tasks_completed": 19,
                    "tasks_failed": 0,
                    "changed_tasks": 8,
                    "skipped_tasks": 1,
                    "user": "backup-automation",
                    "inventory": "production",
                    "extra_vars": {"backup_retention": "7", "compression": "true"}
                }
            ],
            "inventories": [
                {
                    "name": "production",
                    "path": "/opt/ansible/inventories/production.ini",
                    "groups": {
                        "web-servers": ["web-01", "web-02", "web-03", "web-04"],
                        "db-servers": ["db-01", "db-02"],
                        "load-balancers": ["lb-01", "lb-02"], 
                        "monitoring-servers": ["monitor-01", "monitor-02", "monitor-03"],
                        "file-servers": ["fs-01"]
                    },
                    "total_hosts": 12,
                    "last_updated": "2025-01-20T14:30:00Z"
                },
                {
                    "name": "staging",
                    "path": "/opt/ansible/inventories/staging.ini",
                    "groups": {
                        "web-servers": ["staging-web-01", "staging-web-02"],
                        "db-servers": ["staging-db-01"],
                        "monitoring-servers": ["staging-monitor-01"]
                    },
                    "total_hosts": 4,
                    "last_updated": "2025-01-18T09:15:00Z"
                }
            ],
            "coverage": [
                {
                    "category": "Infrastructure Provisioning",
                    "coverage_percentage": 95.2,
                    "automated_tasks": ["Server provisioning", "Network configuration", "Storage setup", "Load balancer config"],
                    "manual_tasks": ["Initial hardware setup", "Physical cabling"],
                    "last_updated": "2025-01-25T20:30:00Z"
                },
                {
                    "category": "Application Deployment", 
                    "coverage_percentage": 98.7,
                    "automated_tasks": ["Code deployment", "Database migrations", "Service restart", "Health checks"],
                    "manual_tasks": ["Final smoke testing"],
                    "last_updated": "2025-01-25T21:15:00Z"
                },
                {
                    "category": "Security Configuration",
                    "coverage_percentage": 87.3,
                    "automated_tasks": ["Firewall rules", "User management", "SSL certificates", "Log forwarding"],
                    "manual_tasks": ["Security audit review", "Compliance verification", "Incident response"],
                    "last_updated": "2025-01-25T18:45:00Z"
                },
                {
                    "category": "Monitoring & Alerting",
                    "coverage_percentage": 92.1, 
                    "automated_tasks": ["Metric collection", "Dashboard setup", "Alert configuration", "Log aggregation"],
                    "manual_tasks": ["Alert tuning", "Dashboard customization"],
                    "last_updated": "2025-01-25T19:20:00Z"
                },
                {
                    "category": "Backup & Recovery",
                    "coverage_percentage": 100.0,
                    "automated_tasks": ["Database backups", "File system backups", "Backup verification", "Retention cleanup"],
                    "manual_tasks": [],
                    "last_updated": "2025-01-25T22:00:00Z"
                }
            ]
        }
    
    async def get_playbooks(self) -> List[Dict[str, Any]]:
        """Get all available playbooks"""
        return self.automation_data["playbooks"]
    
    async def get_executions(self, limit: int = 20, status: Optional[str] = None) -> List[Dict[str, Any]]:
        """Get recent playbook executions"""
        executions = self.automation_data["executions"]
        if status:
            executions = [e for e in executions if e["status"] == status]
        return executions[:limit]
    
    async def get_inventories(self) -> List[Dict[str, Any]]:
        """Get inventory information"""
        return self.automation_data["inventories"]
    
    async def get_automation_coverage(self) -> List[Dict[str, Any]]:
        """Get automation coverage statistics"""
        return self.automation_data["coverage"]

class AnsibleIntegrationService:
    """Complete Ansible automation integration service"""
    
    def __init__(self):
        self.client = MockAnsibleClient()  # In production, use real ansible client
        self.logger = logging.getLogger(__name__)
        
    async def get_automation_overview(self) -> Dict[str, Any]:
        """Get comprehensive automation overview"""
        playbooks = await self.client.get_playbooks()
        executions = await self.client.get_executions(limit=10)
        inventories = await self.client.get_inventories()
        coverage = await self.client.get_automation_coverage()
        
        # Calculate metrics
        total_executions = sum(p["total_runs"] for p in playbooks)
        avg_success_rate = sum(p["success_rate"] for p in playbooks) / len(playbooks)
        recent_failures = len([e for e in executions if e["status"] == "failed"])
        
        total_hosts = sum(inv["total_hosts"] for inv in inventories)
        overall_coverage = sum(c["coverage_percentage"] for c in coverage) / len(coverage)
        
        return {
            "summary": {
                "total_playbooks": len(playbooks),
                "total_executions": total_executions,
                "success_rate": round(avg_success_rate, 2),
                "recent_failures": recent_failures,
                "managed_hosts": total_hosts,
                "automation_coverage": round(overall_coverage, 2)
            },
            "recent_activity": executions[:5],
            "top_playbooks": sorted(playbooks, key=lambda x: x["total_runs"], reverse=True)[:3],
            "timestamp": datetime.utcnow().isoformat()
        }
    
    async def get_playbook_analytics(self) -> Dict[str, Any]:
        """Get detailed playbook analytics"""
        playbooks = await self.client.get_playbooks()
        executions = await self.client.get_executions()
        
        # Playbook performance analysis
        playbook_stats = []
        for playbook in playbooks:
            # Calculate metrics
            recent_executions = [e for e in executions if e["playbook"] == playbook["name"]]
            
            playbook_stats.append({
                "name": playbook["name"],
                "description": playbook["description"],
                "performance": {
                    "success_rate": playbook["success_rate"],
                    "avg_duration": playbook["avg_duration"],
                    "total_runs": playbook["total_runs"],
                    "tasks_count": playbook["tasks_count"]
                },
                "reliability": {
                    "recent_failures": len([e for e in recent_executions if e["status"] == "failed"]),
                    "consistency_score": min(100, playbook["success_rate"] + (100 - len(recent_executions) * 2))
                },
                "usage": {
                    "target_hosts": len(playbook["hosts"]),
                    "last_run": playbook["last_run"],
                    "frequency": "High" if playbook["total_runs"] > 50 else "Medium" if playbook["total_runs"] > 20 else "Low"
                }
            })
        
        # Execution trends
        execution_trends = {
            "daily_executions": [],
            "success_trends": [],
            "duration_trends": []
        }
        
        # Generate trend data (mock)
        for i in range(7):
            date = (datetime.utcnow() - timedelta(days=i)).strftime("%Y-%m-%d")
            daily_count = random.randint(5, 15)
            success_rate = random.uniform(85, 98)
            avg_duration = random.randint(300, 900)
            
            execution_trends["daily_executions"].append({"date": date, "count": daily_count})
            execution_trends["success_trends"].append({"date": date, "success_rate": round(success_rate, 2)})
            execution_trends["duration_trends"].append({"date": date, "avg_duration": avg_duration})
        
        return {
            "playbook_analytics": playbook_stats,
            "execution_trends": execution_trends,
            "performance_insights": {
                "fastest_playbook": min(playbooks, key=lambda x: x["avg_duration"])["name"],
                "most_reliable": max(playbooks, key=lambda x: x["success_rate"])["name"],
                "most_used": max(playbooks, key=lambda x: x["total_runs"])["name"],
                "needs_attention": [p["name"] for p in playbooks if p["success_rate"] < 90]
            },
            "timestamp": datetime.utcnow().isoformat()
        }
    
    async def get_infrastructure_coverage(self) -> Dict[str, Any]:
        """Get infrastructure automation coverage"""
        coverage = await self.client.get_automation_coverage()
        inventories = await self.client.get_inventories()
        
        # Coverage analysis
        coverage_by_category = {}
        for category in coverage:
            coverage_by_category[category["category"]] = {
                "percentage": category["coverage_percentage"],
                "automated_tasks": len(category["automated_tasks"]),
                "manual_tasks": len(category["manual_tasks"]),
                "improvement_potential": 100 - category["coverage_percentage"],
                "tasks": {
                    "automated": category["automated_tasks"],
                    "manual": category["manual_tasks"]
                }
            }
        
        # Host coverage
        total_hosts = sum(inv["total_hosts"] for inv in inventories)
        managed_groups = {}
        for inv in inventories:
            for group, hosts in inv["groups"].items():
                if group not in managed_groups:
                    managed_groups[group] = []
                managed_groups[group].extend(hosts)
        
        return {
            "overall_coverage": round(sum(c["coverage_percentage"] for c in coverage) / len(coverage), 2),
            "coverage_by_category": coverage_by_category,
            "infrastructure_scope": {
                "total_managed_hosts": total_hosts,
                "host_groups": {group: len(hosts) for group, hosts in managed_groups.items()},
                "environments": len(inventories)
            },
            "automation_maturity": {
                "level": "Advanced" if sum(c["coverage_percentage"] for c in coverage) / len(coverage) > 90 else "Intermediate",
                "recommendations": [
                    "Automate remaining security compliance tasks",
                    "Implement self-healing automation patterns", 
                    "Add predictive failure detection",
                    "Enhance error handling and rollback mechanisms"
                ]
            },
            "timestamp": datetime.utcnow().isoformat()
        }
    
    async def get_execution_monitoring(self) -> Dict[str, Any]:
        """Get real-time execution monitoring"""
        executions = await self.client.get_executions(limit=50)
        
        # Current status
        running_executions = []  # Would check for actually running executions
        recent_executions = executions[:10]
        
        # Execution statistics
        successful_executions = [e for e in executions if e["status"] == "successful"]
        failed_executions = [e for e in executions if e["status"] == "failed"]
        
        # Performance metrics
        avg_duration = sum(e["duration"] for e in executions) / len(executions)
        total_hosts_managed = sum(e["hosts_targeted"] for e in executions)
        total_tasks_executed = sum(e["tasks_completed"] for e in executions)
        
        # Error analysis
        error_analysis = {}
        for execution in failed_executions:
            if "error_details" in execution:
                for error in execution["error_details"]:
                    error_type = error["task"]
                    if error_type not in error_analysis:
                        error_analysis[error_type] = {"count": 0, "examples": []}
                    error_analysis[error_type]["count"] += 1
                    error_analysis[error_type]["examples"].append(error["error"])
        
        return {
            "execution_status": {
                "currently_running": len(running_executions),
                "completed_today": len([e for e in executions if e["started_at"].startswith(datetime.utcnow().strftime("%Y-%m-%d"))]),
                "success_rate_24h": round((len(successful_executions) / len(executions)) * 100, 2) if executions else 0
            },
            "recent_executions": recent_executions,
            "performance_metrics": {
                "avg_execution_time": round(avg_duration, 2),
                "total_hosts_managed": total_hosts_managed,
                "total_tasks_executed": total_tasks_executed,
                "change_rate": round(sum(e["changed_tasks"] for e in executions) / total_tasks_executed * 100, 2) if total_tasks_executed > 0 else 0
            },
            "error_analysis": dict(list(error_analysis.items())[:5]),  # Top 5 error types
            "alerts": [
                {"severity": "warning", "message": f"{len(failed_executions)} executions failed in the last 24 hours"} if failed_executions else {"severity": "info", "message": "All recent executions completed successfully"},
                {"severity": "info", "message": f"Average execution time: {round(avg_duration/60, 1)} minutes"}
            ],
            "timestamp": datetime.utcnow().isoformat()
        }

# Create global instance
ansible_service = AnsibleIntegrationService()

if __name__ == "__main__":
    # Test the integration
    async def test_ansible_integration():
        print("ü§ñ Testing Ansible Integration")
        print("=" * 50)
        
        # Test automation overview
        overview = await ansible_service.get_automation_overview()
        print(f"‚úÖ Playbooks: {overview['summary']['total_playbooks']}")
        print(f"‚úÖ Success Rate: {overview['summary']['success_rate']}%")
        print(f"‚úÖ Managed Hosts: {overview['summary']['managed_hosts']}")
        print(f"‚úÖ Coverage: {overview['summary']['automation_coverage']}%")
        print()
        
        # Test playbook analytics
        analytics = await ansible_service.get_playbook_analytics()
        print("üìä Top Performing Playbooks:")
        for playbook in analytics["playbook_analytics"][:3]:
            print(f"  ‚Ä¢ {playbook['name']}: {playbook['performance']['success_rate']}% success")
        print()
        
        # Test infrastructure coverage
        coverage = await ansible_service.get_infrastructure_coverage()
        print(f"üèóÔ∏è Infrastructure Coverage: {coverage['overall_coverage']}%")
        print(f"üñ•Ô∏è Managed Hosts: {coverage['infrastructure_scope']['total_managed_hosts']}")
        print()
        
        # Test execution monitoring
        monitoring = await ansible_service.get_execution_monitoring()
        print(f"‚ö° Executions Today: {monitoring['execution_status']['completed_today']}")
        print(f"üìà Success Rate (24h): {monitoring['execution_status']['success_rate_24h']}%")
        
        print("\n‚úÖ Ansible integration test completed successfully!")
    
    asyncio.run(test_ansible_integration())